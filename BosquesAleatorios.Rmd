---
title: "Regresión logística"
author: "Sergio Martí"
date: "`r Sys.Date()`"
output: html_document
---

## Modelo de "*Random Forest*" o bosque aleatorio.

El modelo de "*Random Forest*" o bosque aleatorio es un método de clasificación que se utiliza para la selección de variables. 

Respecto a la selección de variables, destacar que existen diferentes métodos. Algunos de estos métodos consisten descartar las variables menos importantes. Ejemplos son la selección de variables basada en filtros y la eliminación recursiva de variables.

La eliminación recursiva se realiza a través de la función `rfe()` de la librería `caret`. El funcionamiento es el siguiente: se genera un subconjunto con todas las variables predictoras (numericas y categóricas), y haciendo uso de un clasificador, se evalua la significancia de cada variable. A continuación, se genera otro subconjunto de menor tamaño con las variables más significativas. Este proceso se repite de forma recursiva para cada conjunto, hasta llegar al tamaño deseado.

En este caso, se requiere construir un modelo de clasificación basado en bosques aleatorios (`rfFuncs`).

Tanto la eliminación recursiva de variables, como la construcción del modelo de bosques aleatorios, tienen un coste computacional elevado. Por lo tanto, las funciones requeridas se ejecuta una sola vez y los resultados obtenidos se guardan como archivos "`.RDS`"; para evitar tener que volver a ejecutar las mismas tareas.

```{r}
# Cargar la librería caret
library(caret)
```

Como se ha explicado, los procesos a ejecutar en esta fase, son computacionalmente costosos. Por ello, se va a utilizar la librería "`doParallel`" que permite ejecutar procesos utilizando varios nucleos del ordenador. En este caso, se han utilizado cuatro nucleos mediante la función "`registerDoParallel()`".

```{r}
# Cargar la librería doParallel
library(doParallel)

registerDoParallel(cores=4)
```

Además, algunas funciones hacen sus calculos a partir de números aleatorios. Para poder asegurar la reproducibilidad de los datos, se va a configurar la semilla a partir de la cual se generan los números pseudo-aleatorios. De esa forma siempre saldrán los mismos resultados.

```{r}
# Semilla aleatoria
set.seed(123)
```

### Datos clínicos

Para trabajar con los datos clínicos, se ha decidido eliminar las variables altamente correlacionadas.

```{r}
# Cargar los datos
dfClinical <- readRDS("./dfClinical.RDS")
dfSelectedVars <- readRDS("./selectedVars.RDS")

# Seleccionar las variables numéricas
dfVars <- data.frame(dfSelectedVars[,3:ncol(dfSelectedVars)])

# Seleccionar las variables categóricas
vColsFac <- sapply(dfClinical, is.factor)

# Seleccionar las variables de tipo lógico
vColsLogic <- sapply(dfClinical, is.logical)

# Obtener las variables categóricas y lógicas
dfFac <- dfClinical[,vColsFac]
dfLogic <- dfClinical[,vColsLogic]

# Añadir la columna del factor, las variables categóricas y las lógicas
# dfVars <- cbind(resp.pCR=dfClinical$resp.pCR, dfVars, dfFac, dfLogic)
dfVars <- cbind(resp.pCR=dfClinical$resp.pCR, dfVars)

# Reformular la variable resp.pCR porque si no caret da un error
dfVars$resp.pCR <- factor(dfVars$resp.pCR, levels=c("TRUE", "FALSE"), labels=c("Responde", "No responde"))

# Eliminar variables que no se van a utilizar
rm(vColsFac, vColsLogic, dfFac, dfLogic)
```

Además, se va a crear un data frame con menos datos, para poder realizar pruebas.

```{r}
# Crear un dataframe con datos reducido
vRows <- sample(1:nrow(dfVars), nrow(dfVars) * 0.10)
dfSmall <- dfVars[vRows,]
rm(vRows)
```

A continuación, se va a definir el modelo de selección mediante bosques aleatorios.

```{r}
# Modelo de clasificación de bosques aleatorios
folds = 4
seeds <- sample.int(1000, folds +1)

ctrl.rfranker.cv.4 <- sbfControl(functions = rfSBF,
                                method = "cv", number = folds,
                                seeds = seeds,
                                verbose = FALSE,
                                allowParallel = TRUE)
```

#### Selección mediante filtros

Para seleccionar variables mediante filtros se realiza la siguiente operación:

```{r}
# Filtrado mediante bosques aleatorios
set.seed(234)

rf.ranker.cv.4 <- sbf(resp.pCR ~ ., data=dfVars, sbfControl = ctrl.rfranker.cv.4)

rf.ranker.cv.4
```

#### Selección recursiva

Para seleccionar variables mediante eliminación recursiva se realiza la siguiente operación:

```{r}
#Eliminación recursiva RandomForest:
subsets <- c(3:40)

set.seed(123)

seeds <- vector(mode = "list", length = 6)

for(i in 1:10) {
  seeds[[i]] <- sample.int(1000, length(subsets) + 1)
}

seeds[[11]] <- sample.int(1000, 1)

ctrl.rf.rfe.cv.2 <- rfeControl(functions = rfFuncs, 
                                     method = "cv", 
                                     number = 2, 
                                     seeds = seeds,
                                     returnResamp="final", 
                                     verbose = TRUE,
                                     allowParallel = TRUE)

set.seed(342)

rf.rfe.cv.2 <- rfe(resp.pCR ~ ., data = dfVars, sizes = subsets, rfeControl = ctrl.rf.rfe.cv.2)

# --- Resultados --- #

# Resultados del modelo de random forest
rf.rfe.cv.2

# Número de variables
rf.rfe.cv.2$bestSubset

# Las variables
rf.rfe.cv.2$optVariables

# Accuracy
rf.rfe.cv.2$results[rf.rfe.cv.2$results$Variables == rf.rfe.cv.2$bestSubset, "Accuracy"]

# Matriz de confusión
rf.rfe.cv.2$fit$confusion

# Importancia
rf.rfe.cv.2$fit$importance


varImp(ctrl.rf.rfe.cv.2)
```

Las variables clínicas más importantes según el modelo de bosques aleatorios son siete:

-   "**PGR.log2.tpm**":

-   "**median_lymph_KDE_knn_50**":

-   "**Danaher.Neutrophils**":

-   "**ESC.ssgsea.notnorm**":

-   "**HRD.LST**":

-   "**Danaher.Mast.cells**":

-   "**Swanton.PaclitaxelScore**":

Destacar que coínciden la mayoría de variables seleccionadas mediante el modelo de regresión lineal y la eliminación recursiva de variables. Por lo tanto, al obtener resultados similares con dos métodos distintos, se puede remarcar la relevancia de estas variables a la hora de determinar si el tratamiento neoadyuvante funcionará o no en las pacientes diagnosticadas con cáncer de mama.

Por último, guardamos los resultados como archivos "`.RDS`" con la función "`saveRDS()`".

```{r}
# Guardar los archivos RDS
saveRDS(rf.rfe.cv.2, "./randomForestResult.RDS")
```
