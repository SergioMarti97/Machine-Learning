---
title: "Regresión logística"
author: "Sergio Martí"
date: "`r Sys.Date()`"
output: html_document
---

## Regresión logística

Se pide elaborar sendos modelos de regresión logística para predecir la respuesta al tratamiento. La respuesta de la paciente al tratamiento se almacena en el factor "**resp.pCR**". El modelo tratará de predecir la probabilidad de que la paciente responda satisfactoriamente al tratamiento, es decir, que la variable "**resp.pCR**" sea verdad. A parte, se tratará de determinar cual de las variables numéricas son más importantes y tendrán más peso a la hora de establecer la predicción, así como si van a ser suficientes o el modelo quedará incompleto y deberá ser completado.

```{r}
# Cargar los datos
dfClinical <- readRDS("./dfClinical.RDS")
dfSelectedVars <- readRDS("./selectedVars.RDS")

# Escalar los datos
dfVars <- data.frame(scale(dfSelectedVars[,3:ncol(dfSelectedVars)]))

# Añadir la columna del factor
dfVars <- cbind(resp.pCR=dfClinical$resp.pCR, dfVars)

# Visualizar las variables que se van a utilizar para el modelo
str(dfVars)
```

### Test previo

Antes de construir el modelo de regresión logística, se va a proceder a visualizar las variables en función del factor "**resp.pCR**". Además, se va a realizar un contraste de igualdad de medias para dos poblaciones independientes. De esta forma, se puede comprobar si el efecto del factor "**resp.pCR**" produce diferencias significativas en las variables.

Determinar que variables se ven afectadas o no por el efecto del factor puede servir para descartar algunas variables que no sean relevantes para construir el modelo de regresión logística.

```{r}
# Aplicar un constraste de igualdad de medias para dos poblaciones independientes.
# Encontraremos las variables donde el factor "resp.pCR" proboca diferencias significativas
lColsAvgAreDiff <- lapply(2:ncol(dfVars), function(i) {
  
  sColName <- colnames(dfVars)[i]
  v <- dfVars[[i]]
  
  pob1 <- dfVars[dfVars$resp.pCR == TRUE,i]
  pob2 <- dfVars[dfVars$resp.pCR == FALSE,i]
  
  tVarTest <- var.test(pob1, pob2)
  bHomoscedasticity <- tVarTest$p.value > 0.05
  
  tT.Test <- t.test(pob1, pob2, 
                    alternative = "two.sided", 
                    paired = FALSE, 
                    var.equal = bHomoscedasticity)
  
  bAvgAreDiff <- tT.Test$p.value < 0.05 
  
  ggplot2::ggplot(dfVars, ggplot2::aes(x = resp.pCR, y = v)) + 
    ggplot2::geom_boxplot(color = ifelse(bAvgAreDiff, "red", "black")) + 
    ggplot2::stat_summary(fun=mean, geom="point", size=2, color="red") + 
    ggplot2::labs(title=paste0(sColName, " según resp.pCR"), x="resp.pCR", y=sColName) + 
    ggplot2::theme_classic()
  
  return(bAvgAreDiff)
})

# Convertimos la lista a un vector
vColsAvgAreDiff <- unlist(lColsAvgAreDiff)
rm(lColsAvgAreDiff)

# Mostramos el número de variables que no presentan diferencias significativas
sprintf("Número de variables que se ven afectadas por el factor resp.pCR: %d", sum(vColsAvgAreDiff))
colnames(dfVars[,2:ncol(dfVars)])[!vColsAvgAreDiff]
```

### Primer modelo de regresión logística

Contruir el modelo de regresión logística. Este paso se realiza mediante la función `glm()`.

```{r}
# Descartar variables que no presentan diferencias significativas
dfVars <- dfVars[,vColsAvgAreDiff] # Se puede incluir o no, las variables descartadas no son relevantes

# Construcción del modelo de regresión logistica con todas las variables
modeloCompleto <- glm(resp.pCR ~ ., family = binomial(link="logit"), data = dfVars)

# Mostrar los datos del modelo
summary(modeloCompleto)
```

Calcular los coeficientes, las odds-ratio, y los intervalos de confianza del modelo.

```{r}
# Odds ratio
coefficients(modeloCompleto)
exp(coefficients(modeloCompleto))

# Intervalo confianza
confint(modeloCompleto)
exp(confint(modeloCompleto))
```

Las variables más significativas en el modelo de regresión logística, por orden, son: "**TIDE.CD8**", "**Danaher.CD8.T.cells**", "**Danaher.Mast.cells**", "**Danaher.Neutrophils**", "**Age.at.diagnosis**" y "**PGR.log2.tpm**".

### Segundo modelo de regresión logística

Utilizar todas las variables no tiene porque mejorar el modelo. Muchas de ellas pueden introducir error y empeorar la capacidad predictiva.

Con el fin de mejorar el modelo, se pueden reducir el número de variables utilizadas. Se hará uso de la función `stepAIC()` de la librería `MASS` para seleccionar las variables significativas. Esta función, crea varios modelos y los compara al ir agregando variables.

Se calcula un estadístico llamado "AIC", que cuantifica la información que se pierde debido a la simplificación. Durante el proceso, se comprueba si el valor AIC crece o decrece. Este valor cuantifica la información que se pierde debido a la simplifación, por ello, es mejor el modelo con el valor más bajo de "AIC".

```{r, results = 'hide'}
# Cargar la librería MASS
library(MASS)

# Crear un modelo sin variables
modeloVacio <- glm(resp.pCR ~ 1, family='binomial', data = dfVars)

# Crear el modelo con las variables optimas
modeloOptimo <- stepAIC(modeloVacio, scope = list(lower=modeloVacio, upper=modeloCompleto), direction = 'both')
```

Mediante la función `stepAIC()`, se ha construido un modelo de regresión logística con menos variables que el modelo completo. Estas son las variables utilizadas:

```{r}
# Datos del modelo optimo
summary(modeloOptimo)
```

Se ha determinado que el modelo que minimiza el valor de "AIC" es aquel que utiliza las variables: "**PGR.log2.tpm**", "**Age.at.diagnosis**", "**Danaher.Neutrophils**", "**Swanton.MitosisScore**", "**median_lymph_KDE_knn_50**", "**GGI.gsva**", "**TIDE.TAM.M2**". Las dos últimas variables son las menos significativas. Los coeficientes, odds-ratio y intervalos de confianza del modelo son los siguientes:

```{r}
# Odds ratio
coefficients(modeloOptimo)
exp(coefficients(modeloOptimo))

# Intervalo confianza
confint(modeloOptimo)
exp(confint(modeloOptimo))
```

### Validez de los modelos

Para comprobar la validez de los modelos, se debe de realizar un test de Hosmer-Lemeshow.

```{r}
library("ResourceSelection")

# Modelo completo
hoslem.test(dfVars$resp.pCR, fitted(modeloCompleto))
anova(modeloCompleto, test='Chisq')

# Modelo optimo
hoslem.test(dfVars$resp.pCR, fitted(modeloOptimo))
anova(modeloOptimo, test='Chisq')
```

## Capacidad de predicción de los modelos

Se debe de comprobar la capacidad de predicción del modelo. La finalidad del modelo es determinar si una paciente, en base a sus variables clínicas, va a responder de forma satisfactoria al tratamiento. La forma de comprobarlo es mediante una curva ROC y la matriz de confusión.

Se han construido dos modelos de regresión logística:

-   **Modelo completo**: modelo con todas las variables clínicas, seleccionadas en base a su correlación para evitar el problema de la colinealidad.

-   **Modelo optimo**: modelo construido con la función `stepAIC()`, para seleccionar solamente las variables más relevantes.

Se va a comprobar la capacidad de predicción de los dos modelos para poder compararlos entre si y seleccionar al mejor.

Primero, se procederá a graficar las curvas ROC de los dos modelos.

```{r}
library('ROCR')
library('Epi')

# Curva ROC primer modelo
plot(performance(prediction(modeloCompleto$fitted.values,dfVars$resp.pCR),'tpr','fpr'),
colorize=T, main='Curva ROC')

# Curva ROC segundo modelo
plot(performance(prediction(modeloOptimo$fitted.values,dfVars$resp.pCR),'tpr','fpr'),
colorize=T, main='Curva ROC')
```

A continuación, se determinará el punto de corte óptimo y se construirá las matrices de confusión para los dos modelos:

```{r}
# Modelo completo (todas las variables)

# Curva ROC
curva <- ROC(form=resp.pCR ~ ., data=dfVars, plot='ROC', PV=T, MX=T, AUC=T)

# Matriz de confusión
prediccion <- ifelse(modeloCompleto$fitted.values > 0.337, "True", "False")

mConfusion <- table(modeloCompleto$model$resp.pCR, prediccion, dnn=c("observaciones", "predicciones"))

mConfusion

# ----------------------------------------

# Modelo optimo (solo las variables más importantes)

# Curva ROC TODO
curva <- ROC(form=resp.pCR ~ PGR.log2.tpm + Age.at.diagnosis + TIDE.CD8 + Danaher.Mast.cells + CytScore.log2 + Danaher.Macrophages, data=dfVars, plot='ROC', PV=T, MX=T, AUC=T)

# Matriz de confusión
prediccion <- ifelse(modeloOptimo$fitted.values > 0.289, "True", "False")

mConfusion <- table(modeloOptimo$model$resp.pCR, prediccion, dnn=c("observaciones", "predicciones"))

mConfusion
```

Comparando las curvas ROC, el área bajo la curva que acumulan, y las matrices de confusión, el modelo de regresión logística que incluye todas las variables tiene mayor capacidad de predicción que el modelo que incluye menos variables. Ambos modelos presentan buenas metricas y un alto poder de predicción.

-   **Modelo completo**: utiliza 32 variables, sensibilidad del 89,5%; especificidad del 92,7% y el área bajo la curva es de 0,93. Con los datos que se dispone de las pacientes, clasifica erroneamente 14 pacientes. Determina 4 falsos positivos y 10 "positivos falsos" (clasifica como que no responderán al tratamiento pacientes que sí han respondido al tratamiento).

-   **Modelo óptimo**: utiliza 7 variables, sensibilidad del 81,6%; especificidad del 81,7% y el área bajo la curva es de 0,86. En la matriz de confusión, clasifica erroneamene 28 pacientes, 8 como falsos positivos y 20 "positivos falsos".

Es lógico que suceda esto porque menos variables puede implicar un menor poder de predicción porque no se cuenta con la misma información. Sin embargo, el **modelo completo** utiliza 32 variables mientras que el **modelo óptimo** utiliza 7. La diferencia de sensibilidad entre el modelo completo y el modelo óptimo son 8 puntos de sensibilidad y 11 puntos de especificidad. Lo mejor para elegir entre los dos modelos es encontrar un compromiso entre el número de variables a utilizar (ya que no siempre se podrán obtener todas las variables de la paciente) y la especifidad del modelo.

Esta comparación también sirve para comprobar que las variables seleccionadas en el modelo óptimo son las más relevantes a la hora de determinar si la paciente responderá de manera satisfactoria al tratamiento.
